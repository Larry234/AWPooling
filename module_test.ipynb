{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90fedeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "path = 'HPO/tiny-imagenet/vgg16aw'\n",
    "csv_path = glob(os.path.join(path, '**', 'progress.csv'))\n",
    "json_path = glob(os.path.join(path, '**', 'params.json'))\n",
    "tems = []\n",
    "accs = []\n",
    "\n",
    "for c, j in zip(csv_path, json_path):\n",
    "    trial_name = \"\"\n",
    "    csv_f = pd.read_csv(c)\n",
    "    accs.append(max(csv_f['accuracy']))\n",
    "    f = open(j)\n",
    "    json_f = json.load(f)\n",
    "    \n",
    "    params = list(json_f.keys())[-5:]\n",
    "    values = list(json_f.values())[-5:]\n",
    "    for t, v in zip(params, values):\n",
    "        trial_name += f'{t}={v},'\n",
    "    tems.append(trial_name)\n",
    "        \n",
    "df = pd.DataFrame({'tems': tems, 'accs': accs})\n",
    "df = df.sort_values(by=['accs'], ascending=False)\n",
    "df.to_csv(os.path.join(path, 'best.csv'), index=False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "04bb8f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from models.awpooling import *\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from models.vggaw import VGG11AW, VGG11AWT\n",
    "import os\n",
    "\n",
    "h = 1e-4\n",
    "writer = SummaryWriter(log_dir=os.path.join('Gradient_analysis', f'delta={h}'))\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "ds = ImageFolder(root='/home/larry/Datasets/tiny-imagenet-200/train', transform=transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "]))\n",
    "loader = torch.utils.data.DataLoader(ds, shuffle=True, batch_size=128, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9d9bb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_class=200):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        self.aw1 = AWPool2d_()\n",
    "\n",
    "        # self.conv2 = nn.Sequential(\n",
    "        #     nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.BatchNorm2d(128),\n",
    "        #     nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.BatchNorm2d(128),\n",
    "        # )\n",
    "        # self.aw2 = AWPool2d_()\n",
    "    \n",
    "        self.globalavg = nn.AdaptiveAvgPool2d(1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64, 256),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(),\n",
    "            nn.Linear(256, num_class),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.aw1(x)\n",
    "        x = self.globalavg(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self) -> None:\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    def set_t(self, t):\n",
    "        self.aw1.t = t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fdc7e7a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (aw1): AWPool2d_()\n",
       "  (globalavg): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=256, out_features=200, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "params = [{'params': p, 'lr': 0.1} for n, p in model.named_parameters() if 'aw' not in n]\n",
    "optimizer = torch.optim.SGD(params)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dd9004d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(loader):\n",
    "    model.aw1.t.requires_grad = True\n",
    "    images, label = data\n",
    "    images = images.to(device)\n",
    "    label = label.to(device)\n",
    "\n",
    "    # Autograd\n",
    "    logits = model(images)\n",
    "    base_loss = criterion(logits, label)\n",
    "    base_loss.backward()\n",
    "    writer.add_scalar('Automatic gardient', model.aw1.t.grad, i)\n",
    "\n",
    "    # caculate numercial difference\n",
    "    with torch.no_grad():\n",
    "        model.aw1.t.requires_grad = False\n",
    "        origin_t = model.aw1.t.item()\n",
    "\n",
    "        # forward\n",
    "        model.aw1.t.copy_(torch.tensor(origin_t + h))\n",
    "        logits = model(images)\n",
    "        forward_loss = criterion(logits, label)\n",
    "\n",
    "        # backward\n",
    "        model.aw1.t.copy_(torch.tensor(origin_t - h))\n",
    "        logits = model(images)\n",
    "        backward_loss = criterion(logits, label)\n",
    "\n",
    "        writer.add_scalar('Forward difference', (forward_loss - base_loss) / h, i)\n",
    "        writer.add_scalar('Backward difference', (base_loss - backward_loss) / h, i)\n",
    "        writer.add_scalar('Central difference', (forward_loss - backward_loss) / (2 * h), i)\n",
    "\n",
    "    model.aw1.t.copy_(torch.tensor(origin_t))\n",
    "\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    model.aw1.t.grad.zero_()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec93eae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4dbf843a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-56a11fc98e5285b0\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-56a11fc98e5285b0\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir Gradient_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "700f21ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0037], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "logits = model(x)\n",
    "loss = criterion(logits, y)\n",
    "loss.backward()\n",
    "print(model.aw1.t.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183e311d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.aw1.t.requires_grad = False\n",
    "logits = model(x)\n",
    "base = criterion(logits, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c9a0ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0019999742507935\n",
      "0.9980000257492065\n",
      "base loss: 5.295560836791992\n",
      "forward loss: 5.295570373535156\n",
      "backward loss: 5.29556131362915\n",
      "forward difference: 0.004768371116369963\n",
      "backward difference: -0.00023841856454964727\n",
      "central difference: 0.0022649762686342\n"
     ]
    }
   ],
   "source": [
    "# compute forward loss\n",
    "model.aw1.t.copy_(torch.tensor(origin_t + h))\n",
    "print(model.aw1.t.item())\n",
    "logits = model(x)\n",
    "forward = criterion(logits, y)\n",
    "model.aw1.t.copy_(torch.tensor(origin_t - h))\n",
    "print(model.aw1.t.item())\n",
    "logits = model(x)\n",
    "backward = criterion(logits, y)\n",
    "\n",
    "model.aw1.t.copy_(torch.tensor(origin_t))\n",
    "print(f'base loss: {base.item()}\\nforward loss: {forward.item()}\\nbackward loss: {backward.item()}\\n'\\\n",
    "      f'forward difference: {(forward - base) / h}\\n'\\\n",
    "      f'backward difference: {(base - backward) / h}\\n'\\\n",
    "      f'central difference: {(forward - backward) / (2 * h)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5443a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_numerical(model, func, x, h=1e-4):\n",
    "    logits = func(x)\n",
    "    forward = func(x + h)\n",
    "    backward = func(x - h)\n",
    "\n",
    "    print(f'forward difference {(forward - logits) / h}\\nbackward difference: {(logits - backward) / h}\\ncentral difference: {(forward-backward)/ (2* h)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051beef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_t(x, t=1):\n",
    "    return np.exp(x / t) / np.sum(np.exp(x / t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b23a194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_pool(x, t):\n",
    "    return x.dot(softmax_t(x, t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e20e9a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05000000074505806 tensor(3.)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor(0.05)\n",
    "b = a.item()\n",
    "a.copy_(torch.tensor(3))\n",
    "print(b, a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92eeda3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AWPooling",
   "language": "python",
   "name": "awpooling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
